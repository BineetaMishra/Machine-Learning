{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "1. importing the library\n",
    "2. reading and importing the training and testing dataset (here the dataset is split into two from before- train and test)\n",
    "3. Feature Scaling\n",
    "4. Training the Decission Tree model on training data set.\n",
    "5. Predicting a new reult on train data and test data.\n",
    "6. #Making the Confusion Matrix for training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "train_data = pd.read_csv('C:\\\\Users\\\\ebineet\\\\Documents\\\\Machine Learning\\\\Machine+Learning+A-Z+(Codes+and+Datasets)\\\\Machine Learning A-Z (Codes and Datasets)\\\\Part 3 - Classification\\\\Section 19 - Decision Tree Classification\\\\Python\\\\AnalyticsVidhya\\\\train-data.csv')\n",
    "train_x = train_data.iloc[:, :-1].values\n",
    "train_y = train_data.iloc[:, -1].values\n",
    "test_data = pd.read_csv('C:\\\\Users\\\\ebineet\\\\Documents\\\\Machine Learning\\\\Machine+Learning+A-Z+(Codes+and+Datasets)\\\\Machine Learning A-Z (Codes and Datasets)\\\\Part 3 - Classification\\\\Section 19 - Decision Tree Classification\\\\Python\\\\AnalyticsVidhya\\\\test-data.csv')\n",
    "test_x = test_data.iloc[:, :-1].values\n",
    "test_y = test_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_x = sc.fit_transform(train_x)\n",
    "test_x = sc.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the Test set results for training data\n",
    "pred_train = classifier.predict(train_x)\n",
    "#print(np.concatenate((pred_train.reshape(len(pred_train),1), train_y.reshape(len(train_y),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the Test set results for testing data\n",
    "pred_test = classifier.predict(test_x)\n",
    "#print(np.concatenate((pred_test.reshape(len(pred_test),1), test_y.reshape(len(test_y),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[431   1]\n",
      " [  9 271]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9859550561797753"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the Confusion Matrix for training data\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(train_y,pred_train)\n",
    "print(cm)\n",
    "accuracy_score(train_y,pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 23]\n",
      " [13 49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7988826815642458"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the Confusion Matrix for testing data\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(test_y, pred_test)\n",
    "print(cm)\n",
    "accuracy_score(test_y, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "1. importing the library\n",
    "2. reading and importing the training and testing dataset (here the dataset is split into two from before- train and test)\n",
    "3. Feature Scaling\n",
    "4. Training the Decission Tree model on training data set.\n",
    "5. Predicting a new reult on train data and test data.\n",
    "6. #Making the Confusion Matrix for training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and importing the training and testing dataset (here the dataset is split into two from before- train and test)\n",
    "\n",
    "# read the dataset\n",
    "train_data = pd.read_csv('C:\\\\Users\\\\ebineet\\\\Documents\\\\Machine Learning\\\\Machine+Learning+A-Z+(Codes+and+Datasets)\\\\Machine Learning A-Z (Codes and Datasets)\\\\Part 3 - Classification\\\\Section 20 - Random Forest Classification\\\\Python\\\\AnalyticsVidhya\\\\train-data.csv')\n",
    "train_x = train_data.iloc[:, :-1].values\n",
    "train_y = train_data.iloc[:, -1].values\n",
    "test_data = pd.read_csv('C:\\\\Users\\\\ebineet\\\\Documents\\\\Machine Learning\\\\Machine+Learning+A-Z+(Codes+and+Datasets)\\\\Machine Learning A-Z (Codes and Datasets)\\\\Part 3 - Classification\\\\Section 20 - Random Forest Classification\\\\Python\\\\AnalyticsVidhya\\\\test-data.csv')\n",
    "test_x = test_data.iloc[:, :-1].values\n",
    "test_y = test_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_x = sc.fit_transform(train_x)\n",
    "test_x = sc.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=2,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Decission Tree model on training data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 2, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting a new reult on train data.\n",
    "pred_train = classifier.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting a new reult on test data.\n",
    "pred_test = classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187   0]\n",
      " [ 17 508]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.976123595505618"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the Confusion Matrix for training data\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(train_y,pred_train)\n",
    "print(cm)\n",
    "accuracy_score(train_y,pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58   0]\n",
      " [ 13 108]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9273743016759777"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the Confusion Matrix for testing data\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(test_y,pred_test)\n",
    "print(cm)\n",
    "accuracy_score(test_y,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
